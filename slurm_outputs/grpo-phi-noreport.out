---------------------------------------------
SLURM job ID:        14647
SLURM job node list: lovelace-01
DATE:                Tue May 20 11:54:31 AM CEST 2025
---------------------------------------------
wandb: Appending key for api.wandb.ai to your netrc file: /u/scandussio/.netrc
wandb: Currently logged in as: saracandussio (saracandussio-universit-degli-studi-di-trieste) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Unsloth 2025.5.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 1,000 | Num Epochs = 3 | Total steps = 375
O^O/ \_/ \    Batch size per device = 6 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (6 x 8 x 1) = 48
 "-____-"     Trainable parameters = 29,884,416/4,000,000,000 (0.75% trained)
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /u/scandussio/rebus-grpo/wandb/run-20250520_115501-dukl98fv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run GRPO-phi
wandb: ‚≠êÔ∏è View project at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/huggingface
wandb: üöÄ View run at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/huggingface/runs/dukl98fv
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.5.4: Fast Mistral patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100 80GB PCIe MIG 1g.10gb. Num GPUs = 1. Max memory: 9.5 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 4 to the `num_generations` of 6
Training begins...
slurmstepd: error: *** JOB 14647 ON lovelace-01 CANCELLED AT 2025-05-20T13:54:58 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
  0%|          | 0/375 [00:00<?, ?it/s]  0%|          | 1/375 [15:02<93:46:46, 902.69s/it]  1%|          | 2/375 [30:00<93:13:10, 899.71s/it]  1%|          | 3/375 [44:56<92:49:11, 898.26s/it]  1%|          | 4/375 [59:54<92:31:55, 897.89s/it]  1%|‚ñè         | 5/375 [1:14:52<92:18:02, 898.06s/it]  2%|‚ñè         | 6/375 [1:29:50<92:02:11, 897.92s/it]  2%|‚ñè         | 7/375 [1:44:46<91:44:23, 897.45s/it]  2%|‚ñè         | 8/375 [1:59:44<91:29:47, 897.51s/it]slurmstepd: error: *** STEP 14647.0 ON lovelace-01 CANCELLED AT 2025-05-20T13:54:58 DUE TO TIME LIMIT ***
