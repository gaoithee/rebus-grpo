---------------------------------------------
SLURM job ID:        14659
SLURM job node list: lovelace-01
DATE:                Tue May 20 04:41:00 PM CEST 2025
---------------------------------------------
wandb: Appending key for api.wandb.ai to your netrc file: /u/scandussio/.netrc
wandb: Currently logged in as: saracandussio (saracandussio-universit-degli-studi-di-trieste) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Unsloth 2025.5.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /u/scandussio/rebus-grpo/wandb/run-20250520_164130-yzlz51p5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-feather-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/llama-GRPO
wandb: üöÄ View run at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/llama-GRPO/runs/yzlz51p5
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 81,318 | Num Epochs = 3 | Total steps = 30,492
O^O/ \_/ \    Batch size per device = 6 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (6 x 8 x 1) = 48
 "-____-"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.5.4: Fast Llama patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.138 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 4 to the `num_generations` of 6
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 14659 ON lovelace-01 CANCELLED AT 2025-05-20T17:09:10 ***
  0%|          | 0/30492 [00:00<?, ?it/s]  0%|          | 1/30492 [04:02<2058:01:52, 242.99s/it]  0%|          | 2/30492 [07:59<2023:21:41, 238.90s/it]  0%|          | 3/30492 [11:55<2012:20:56, 237.61s/it]  0%|          | 4/30492 [15:51<2006:47:37, 236.96s/it]  0%|          | 5/30492 [19:47<2003:38:40, 236.60s/it]  0%|          | 6/30492 [23:42<2001:33:04, 236.36s/it]slurmstepd: error: *** STEP 14659.0 ON lovelace-01 CANCELLED AT 2025-05-20T17:09:10 ***
