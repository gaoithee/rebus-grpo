---------------------------------------------
SLURM job ID:        14485
SLURM job node list: lovelace-01
DATE:                Fri May 16 05:41:40 PM CEST 2025
---------------------------------------------
wandb: Appending key for api.wandb.ai to your netrc file: /u/scandussio/.netrc
wandb: Currently logged in as: saracandussio (saracandussio-universit-degli-studi-di-trieste) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Unsloth 2025.5.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /u/scandussio/rebus-grpo/wandb/run-20250516_174207-03w5i9nu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-flower-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/llama-GRPO
wandb: üöÄ View run at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/llama-GRPO/runs/03w5i9nu
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 81,318 | Num Epochs = 3 | Total steps = 30,492
O^O/ \_/ \    Batch size per device = 6 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (6 x 8 x 1) = 48
 "-____-"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.5.4: Fast Llama patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100 80GB PCIe MIG 1g.10gb. Num GPUs = 1. Max memory: 9.5 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 4 to the `num_generations` of 6
slurmstepd: error: *** JOB 14485 ON lovelace-01 CANCELLED AT 2025-05-16T19:41:49 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
  0%|          | 0/30492 [00:00<?, ?it/s]  0%|          | 1/30492 [24:01<12207:36:45, 1441.32s/it]  0%|          | 2/30492 [47:45<12122:00:22, 1431.26s/it]  0%|          | 3/30492 [1:11:29<12095:07:33, 1428.14s/it]  0%|          | 4/30492 [1:35:12<12075:34:32, 1425.87s/it]  0%|          | 5/30492 [1:58:55<12067:06:26, 1424.92s/it]slurmstepd: error: *** STEP 14485.0 ON lovelace-01 CANCELLED AT 2025-05-16T19:41:49 DUE TO TIME LIMIT ***
