---------------------------------------------
SLURM job ID:        14487
SLURM job node list: lovelace-01
DATE:                Fri May 16 06:02:32 PM CEST 2025
---------------------------------------------
wandb: Appending key for api.wandb.ai to your netrc file: /u/scandussio/.netrc
wandb: Currently logged in as: saracandussio (saracandussio-universit-degli-studi-di-trieste) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Unsloth 2025.5.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /u/scandussio/rebus-grpo/wandb/run-20250516_180258-bqmv2aed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-spaceship-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/phi-GRPO
wandb: üöÄ View run at https://wandb.ai/saracandussio-universit-degli-studi-di-trieste/phi-GRPO/runs/bqmv2aed
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 81,318 | Num Epochs = 3 | Total steps = 30,492
O^O/ \_/ \    Batch size per device = 6 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (6 x 8 x 1) = 48
 "-____-"     Trainable parameters = 29,884,416/4,000,000,000 (0.75% trained)
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.5.4: Fast Mistral patching. Transformers: 4.51.3.
   \\   /|    NVIDIA A100 80GB PCIe MIG 1g.10gb. Num GPUs = 1. Max memory: 9.5 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 4 to the `num_generations` of 6
slurmstepd: error: *** JOB 14487 ON lovelace-01 CANCELLED AT 2025-05-16T20:02:49 DUE TO TIME LIMIT ***
  0%|          | 0/30492 [00:00<?, ?it/s]  0%|          | 1/30492 [15:01<7638:56:32, 901.91s/it]  0%|          | 2/30492 [29:58<7611:44:43, 898.73s/it]  0%|          | 3/30492 [44:55<7603:48:06, 897.82s/it]  0%|          | 4/30492 [59:50<7596:47:34, 897.02s/it]  0%|          | 5/30492 [1:14:47<7593:33:51, 896.67s/it]  0%|          | 6/30492 [1:29:42<7589:17:27, 896.20s/it]  0%|          | 7/30492 [1:44:39<7591:32:32, 896.49s/it]  0%|          | 8/30492 [1:59:36<7592:17:53, 896.61s/it]slurmstepd: error: *** STEP 14487.0 ON lovelace-01 CANCELLED AT 2025-05-16T20:02:49 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
