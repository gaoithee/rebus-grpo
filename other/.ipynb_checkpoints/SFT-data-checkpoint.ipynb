{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22699f5d-a484-4491-9ae9-8d0da5259a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8488582d437a472186503994ef46d3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b1bb415-83a6-4102-b907-a7eff397a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "template = \"\"\"<bos><start_of_turn>user\n",
    "{human}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "{gpt}<|eot_id|>\"\"\"\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [template.format(human=convo[0][\"value\"], gpt=convo[1][\"value\"]) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "dataset_llm = load_dataset('gsarti/eureka-rebus', 'llm_sft', data_files=[\"train.jsonl\"], split = \"train\")\n",
    "dataset_llm = dataset_llm.map(formatting_prompts_func, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acfc7f9f-7e7b-4b52-99c4-64670bd15d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "Risolvi gli indizi tra parentesi per ottenere una prima lettura, e usa la chiave di lettura per ottenere la soluzione del rebus.\n",
      "\n",
      "Rebus: A [Quello di fiori si riceve volentieri] [Vezzi visibili] RL [Dividono l'Argentina dal Cile] SE\n",
      "Chiave di lettura: 8 9<end_of_turn>\n",
      "<start_of_turn>model\n",
      "Procediamo alla risoluzione del rebus passo per passo:\n",
      "- A = A\n",
      "- [Quello di fiori si riceve volentieri] = mazzo\n",
      "- [Vezzi visibili] = nei\n",
      "- R L = R L\n",
      "- [Dividono l'Argentina dal Cile] = Ande\n",
      "- S E = S E\n",
      "\n",
      "Prima lettura: A mazzo nei RL Ande SE\n",
      "\n",
      "Ora componiamo la soluzione seguendo la chiave risolutiva:\n",
      "8 = Amazzone\n",
      "9 = irlandese\n",
      "\n",
      "Soluzione: Amazzone irlandese\n",
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_llm[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8d5e2a8-f6c5-4e3a-85d0-5a6f57dca62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig  # Note: This might be a typo. In your code, you later call LoraConfig.\n",
    "from trl import GRPOConfig, GRPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7193ed3-80c4-45ea-b071-c037ed8eeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt that instructs the model to use a specific XML format.\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Risolvi gli indizi tra parentesi per ottenere una prima lettura, e usa la chiave di lettura per ottenere la soluzione del rebus.\n",
    "\n",
    "\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee56a1d-9602-45be-b5c7-0c314ff84f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML chain-of-thought format template.\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "# Function to extract the answer part from the XML response.\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "# Function to extract an answer if it is provided with a \"####\" delimiter.\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41963a94-6943-461b-92a4-c5fe3087d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('gsarti/eureka-rebus', 'verbalized_rebus', split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bdac1e3-06c4-427f-8566-2719aeb2c569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FRASE': \"Non vi sono difficoltà a l'amore sincero\",\n",
       " 'PRIMALET': 'N O N - viso - nodi - F fico - L T A A L - amo RE - S in cero',\n",
       " 'AUTORE': '-',\n",
       " 'RIVISTA': 'RPC',\n",
       " 'MESE': 0,\n",
       " 'ANNO': 1869,\n",
       " 'TIPO': None,\n",
       " 'NOTE': None,\n",
       " 'WORDS': 'viso nodi fico amo in cero',\n",
       " 'LETTERS': 'N O N F L T A A L R E S',\n",
       " 'FRASE_LEN': \"3 2 4 10 1 1 ' 5 7\",\n",
       " 'FRASE_SEPARATED': \"Non vi sono difficoltà a l ' amore sincero\",\n",
       " 'VERBALIZED_PRIMALET': \"N O N [Volto, faccia] [Possono essere scorsoi] F [C'è anche quello d'India] L T A A L [Un' insidia subacquea] RE S [Alla moda... inglese] [Si accende in chiesa]\",\n",
       " 'VERBALIZED_PRIMALET_WITH_LEN': \"N O N [Volto, faccia (4)] [Possono essere scorsoi (4)] F [C'è anche quello d'India (4)] L T A A L [Un' insidia subacquea (3)] RE S [Alla moda... inglese (2)] [Si accende in chiesa (4)]\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed018e3e-75a4-4a1b-aa0f-b6bb7317fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"{dataset[0]['VERBALIZED_PRIMALET']} \\n\" + f\"{dataset[0]['FRASE_LEN']} \\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c537e-7cb4-44b3-9e5e-db9ab7f69cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70994583-b63f-433e-9780-ab20c2d47def",
   "metadata": {},
   "source": [
    "# altro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cc3ef-5c7a-4df8-8e3b-98cee1c24b35",
   "metadata": {},
   "source": [
    "Sia per le soluzioni delle definizioni che per le parole della soluzione finale, direi:\n",
    "- Differenza di lunghezza con lunghezza giusta\n",
    "- Edit distance tra predicted e correct words\n",
    "- (se si riesce abbastanza rapidamente) semantic similarity tra predicted e correct word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66de7182-ab5c-40f5-9ad9-b118027c565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def extract_solution(text):\n",
    "    match = re.search(r\"Soluzione:\\s*(\\w+\\s\\w+)\", text)\n",
    "    if match:\n",
    "        solution = match.group(1)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986db0be-8e94-4e81-b127-7baa6cb967df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazzone irlandese'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_solution(dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2fdf8-eed1-48a8-b0a1-18ef922aa6a2",
   "metadata": {},
   "source": [
    "- Proportion of correctly guessed words during definition resolution (i.e. `mazzo`, `nei`, ...)\n",
    "- Proportion of correct words and letters in the generated first pass (i.e. `Prima lettura: A mazzo nei RL Ande SE`)\n",
    "- Proportion of generated first passes matching the gold reference (`A-mazzo-nei-RL-ande-SE` - `amazzone-irlandese`)\n",
    "- Proportion of generated solution words (`amazzone`, `irlandese`) matching the lengths specified by the solution key (`8`, `9`)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a6f71-12c2-4567-a986-ff9db5c2a9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
