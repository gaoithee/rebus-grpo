{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d345a9-c42a-498c-aa5b-612f8d1174a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 16:46:00.014918: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-09 16:46:00.057561: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-09 16:46:00.057599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-09 16:46:00.058910: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-09 16:46:00.067171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-09 16:46:01.147078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930d036c-6dc5-4554-9a17-59a7d54bcb71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Gemma3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 1024  # Can increase for longer reasoning traces\n",
    "lora_rank = 32  # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"google/gemma-3-1b-it\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,  # False for LoRA 16bit\n",
    "    fast_inference=False,  # Enable vLLM fast inference\n",
    "    max_lora_rank=lora_rank,\n",
    "    gpu_memory_utilization=0.6,  # Reduce if out of memory\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=lora_rank,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # Remove QKVO if out of memory\n",
    "    lora_alpha=lora_rank,\n",
    "    use_gradient_checkpointing=\"unsloth\",  # Enable long context finetuning\n",
    "    random_state=3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0499a996-963f-4824-a572-4d3fa55582c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt that instructs the model to use a specific format\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9095cc56-5300-47b3-a263-2d4e92af2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "\n",
    "# Helper functions to extract answers from different formats\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "\n",
    "def extract_hash_answer(text: str) -> str:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "\n",
    "# Function to prepare the GSM8K dataset\n",
    "def get_gsm8k_questions(split=\"train\") -> Dataset:\n",
    "    data = load_dataset(\"openai/gsm8k\", \"main\")[split]\n",
    "    data = data.map(\n",
    "        lambda x: {\n",
    "            \"prompt\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": x[\"question\"]},\n",
    "            ],\n",
    "            \"answer\": extract_hash_answer(x[\"answer\"]),\n",
    "        }\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "dataset = get_gsm8k_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52286ca1-f906-4fa3-8216-2c8867056b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward function that checks if the answer is correct\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    q = prompts[0][-1][\"content\"]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    print(\n",
    "        \"-\" * 20,\n",
    "        f\"Question:\\n{q}\",\n",
    "        f\"\\nAnswer:\\n{answer[0]}\",\n",
    "        f\"\\nResponse:\\n{responses[0]}\",\n",
    "        f\"\\nExtracted:\\n{extracted_responses[0]}\",\n",
    "    )\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "\n",
    "# Reward function that checks if the answer is an integer\n",
    "def int_reward_func(completions, **kwargs) -> list[float]:\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "\n",
    "# Reward function that checks if the completion follows the strict format\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "\n",
    "# Reward function that checks if the completion follows a more relaxed format\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "\n",
    "# Reward function that counts XML tags and penalizes extra content\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1]) * 0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1) * 0.001\n",
    "    return count\n",
    "\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5efde07a-cd03-4592-957a-2050b92accdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 6\n",
      "Unsloth: Switching to float32 training since model cannot work with float16\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "max_prompt_length = 256\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate=5e-6,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.99,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,  # Increase to 4 for smoother training\n",
    "    num_generations=6,  # Decrease if out of memory\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_completion_length=max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps=250,\n",
    "    save_steps=250,\n",
    "    max_grad_norm=0.1,\n",
    "    report_to=\"none\",  # Can use Weights & Biases\n",
    "    output_dir=\"outputs\",\n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[\n",
    "        xmlcount_reward_func,\n",
    "        soft_format_reward_func,\n",
    "        strict_format_reward_func,\n",
    "        int_reward_func,\n",
    "        correctness_reward_func,\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069fb7ba-73af-44f1-b10f-4265e192c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 250\n",
      "O^O/ \\_/ \\    Batch size per device = 6 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (6 x 1 x 1) = 6\n",
      " \"-____-\"     Trainable parameters = 26,091,520/1,000,000,000 (2.61% trained)\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 32768, 'top_k': 64, 'top_p': 0.95}. If this is not desired, please set these values explicitly.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Question:\n",
      "A concert ticket costs $40. Mr. Benson bought 12 tickets and received a 5% discount for every ticket bought that exceeds 10. How much did Mr. Benson pay in all? \n",
      "Answer:\n",
      "476 \n",
      "Response:\n",
      "<reasoning>\n",
      "Mr. Benson bought 12 tickets at $40 each. He received a 5% discount on each ticket purchased that exceeds 10. This means he gets a 5% discount on the $40 ticket, which is $40 * 0.05 = $2.00. For each of the 12 tickets, he gets a $2 discount. So the total discount is $2 * 12 = $24. The final price he pays is $40 (original price) - $24 (discount) = $16.\n",
      "</reasoning>\n",
      "<answer>\n",
      "$16\n",
      "</answer> \n",
      "Extracted:\n",
      "$16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9/250 10:42 < 6:08:42, 0.01 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / xmlcount_reward_func</th>\n",
       "      <th>rewards / soft_format_reward_func</th>\n",
       "      <th>rewards / strict_format_reward_func</th>\n",
       "      <th>rewards / int_reward_func</th>\n",
       "      <th>rewards / correctness_reward_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.605333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.653500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n",
      "-------------------- Question:\n",
      "Jane is trying to decide whether to buy a house or a trailer. A house costs $480,000 and a trailer costs $120,000. Each loan will be paid in monthly installments over 20 years. How much more is the monthly payment on the house compared to the trailer? \n",
      "Answer:\n",
      "1500 \n",
      "Response:\n",
      "<reasoning>\n",
      "The monthly payment on the house is significantly higher than the monthly payment on the trailer due to the higher initial cost of the house. A larger initial investment leads to a larger monthly payment. We need to calculate the difference in monthly payments to determine how much more the house costs.\n",
      "\n",
      "</reasoning>\n",
      "<answer>\n",
      "$480,000\n",
      "</answer> \n",
      "Extracted:\n",
      "$480,000\n",
      "-------------------- Question:\n",
      "Janet pays $40/hour for 3 hours per week of clarinet lessons and $28/hour for 5 hours a week of piano lessons. How much more does she spend on piano lessons than clarinet lessons in a year? \n",
      "Answer:\n",
      "1040 \n",
      "Response:\n",
      "Letâ€™s calculate Janetâ€™s total weekly spending on each activity and then find the difference between the two yearly totals.\n",
      "\n",
      "**Clarinet Lessons:**\n",
      "\n",
      "* Hourly rate: $40\n",
      "* Hours per week: 3\n",
      "* Weekly cost: $40 * 3 = $120\n",
      "\n",
      "**Piano Lessons:**\n",
      "\n",
      "* Hourly rate: $28\n",
      "* Hours per week: 5\n",
      "* Weekly cost: $28 * 5 = $140\n",
      "\n",
      "**Yearly Cost of Piano Lessons:**\n",
      "\n",
      "* Weekly cost: $140\n",
      "* Weeks per year: 52\n",
      "* Yearly cost: $140 * 52 = $7080\n",
      "\n",
      "**Difference between Yearly Piano Costs and Clarinet Costs:**\n",
      "\n",
      "* Yearly cost of piano lessons: $7080\n",
      "* Yearly cost of clarinet lessons: $120\n",
      "* Difference: $7080 - $120 = $6960\n",
      "\n",
      "**Answer:** Janet spends $6960 more on piano lessons than on clarinet lessons in a year.\n",
      " \n",
      "Extracted:\n",
      "Letâ€™s calculate Janetâ€™s total weekly spending on each activity and then find the difference between the two yearly totals.\n",
      "\n",
      "**Clarinet Lessons:**\n",
      "\n",
      "* Hourly rate: $40\n",
      "* Hours per week: 3\n",
      "* Weekly cost: $40 * 3 = $120\n",
      "\n",
      "**Piano Lessons:**\n",
      "\n",
      "* Hourly rate: $28\n",
      "* Hours per week: 5\n",
      "* Weekly cost: $28 * 5 = $140\n",
      "\n",
      "**Yearly Cost of Piano Lessons:**\n",
      "\n",
      "* Weekly cost: $140\n",
      "* Weeks per year: 52\n",
      "* Yearly cost: $140 * 52 = $7080\n",
      "\n",
      "**Difference between Yearly Piano Costs and Clarinet Costs:**\n",
      "\n",
      "* Yearly cost of piano lessons: $7080\n",
      "* Yearly cost of clarinet lessons: $120\n",
      "* Difference: $7080 - $120 = $6960\n",
      "\n",
      "**Answer:** Janet spends $6960 more on piano lessons than on clarinet lessons in a year.\n",
      "-------------------- Question:\n",
      "Sabrina is collecting herbs to make a poultice for her grandmother. She needs twice as many basil leaves as sage leaves and 5 fewer sage leaves than verbena leaves. If she needs 12 basil leaves, how many leaves total does she need? \n",
      "Answer:\n",
      "29 \n",
      "Response:\n",
      "<reasoning>\n",
      "The problem states Sabrina needs twice as many basil leaves as sage leaves and 5 fewer sage leaves than verbena leaves. If she needs 12 basil leaves, we need to find out how many leaves she needs in total. This is a problem involving substitution and finding a relationship between the quantities of each herb.\n",
      "\n",
      "<answer>\n",
      "Let the number of sage leaves be 's'.\n",
      "The number of basil leaves is twice the number of sage leaves, so the number of basil leaves is 2s.\n",
      "The number of sage leaves is 5 fewer than the verbena leaves, so the number of sage leaves is s - 5.\n",
      "We are given that she needs 12 basil leaves, so 2s = 12.\n",
      "Dividing both sides by 2, we get s = 6.\n",
      "Now we can find the number of sage leaves: s - 5 = 6 - 5 = 1.\n",
      "So, there are 1 sage leaf.\n",
      "The total number of leaves is the sum of the basil leaves and the sage leaves, which is 12 + 1 = 13.\n",
      "\n",
      "Alternatively, let the number of verbena leaves be 'v'. Then the number of basil leaves is 2v, and the number of sage leaves is v - 5.\n",
      "We are given that the number of basil leaves is 12. So, 2v = 12.\n",
      "Dividing both sides by 2, we get v = 6.\n",
      "Then, the number of sage leaves is 6 - 5 = 1.\n",
      "The total number of leaves is 12 + 1 = 13.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{13}$ \n",
      "Extracted:\n",
      "Let the number of sage leaves be 's'.\n",
      "The number of basil leaves is twice the number of sage leaves, so the number of basil leaves is 2s.\n",
      "The number of sage leaves is 5 fewer than the verbena leaves, so the number of sage leaves is s - 5.\n",
      "We are given that she needs 12 basil leaves, so 2s = 12.\n",
      "Dividing both sides by 2, we get s = 6.\n",
      "Now we can find the number of sage leaves: s - 5 = 6 - 5 = 1.\n",
      "So, there are 1 sage leaf.\n",
      "The total number of leaves is the sum of the basil leaves and the sage leaves, which is 12 + 1 = 13.\n",
      "\n",
      "Alternatively, let the number of verbena leaves be 'v'. Then the number of basil leaves is 2v, and the number of sage leaves is v - 5.\n",
      "We are given that the number of basil leaves is 12. So, 2v = 12.\n",
      "Dividing both sides by 2, we get v = 6.\n",
      "Then, the number of sage leaves is 6 - 5 = 1.\n",
      "The total number of leaves is 12 + 1 = 13.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{13}$\n",
      "-------------------- Question:\n",
      "Over the past five years, on July 4th, the high temperature for Washington, DC has been: 90 degrees in 2020, 90 degrees in 2019, 90 degrees in 2018, 79 degrees in 2017 and 71 degrees in 2016. What is the average temperature for July 4th in Washington, DC over the past 5 years? \n",
      "Answer:\n",
      "84 \n",
      "Response:\n",
      "<reasoning>\n",
      "The question asks for the average temperature for July 4th in Washington, DC over the past five years.  We need to calculate this by summing the temperatures for each year and dividing by the number of years (5).\n",
      "\n",
      "<answer>\n",
      "90.0 \n",
      "Extracted:\n",
      "90.0\n",
      "-------------------- Question:\n",
      "Rene can finish reading 30 pages in 60 minutes. Lulu can read 27 pages in 60 minutes and Cherry can read 25 pages in 60 minutes. If they have been reading for 240 minutes now, how many pages have they finished reading in total? \n",
      "Answer:\n",
      "328 \n",
      "Response:\n",
      "Let $R$ be the number of pages Rene can finish reading in 60 minutes.\n",
      "Let $L$ be the number of pages Lulu can finish reading in 60 minutes.\n",
      "Let $C$ be the number of pages Cherry can finish reading in 60 minutes.\n",
      "We are given that Rene can finish reading 30 pages in 60 minutes, so $R = 30$.\n",
      "We are given that Lulu can read 27 pages in 60 minutes, so $L = 27$.\n",
      "We are given that Cherry can read 25 pages in 60 minutes, so $C = 25$.\n",
      "Rene finishes reading $R$ pages in 60 minutes, so he finishes reading $30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $L$ pages in 60 minutes, so she finishes reading $27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $C$ pages in 60 minutes, so she finishes reading $25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$ pages.\n",
      "They have been reading for 240 minutes.\n",
      "Let $P$ be the total number of pages they have finished reading.\n",
      "Rene finishes reading $30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$.\n",
      "They have been reading for 240 minutes.\n",
      "Let $x$ be the number of pages they have finished reading.\n",
      "Rene finishes reading $R \\times 60 = 30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $L \\times 60 = 27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $C \\times 60 = 25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$.\n",
      "The time they have been reading is 240 minutes.\n",
      "The number of pages they have finished reading is $\\frac{4920}{60} = 82$ pages.\n",
      "However, we are asked how many pages they have finished reading in total.\n",
      "Let $x$ be the number of pages they have finished reading.\n",
      "Rene finishes reading $30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$ pages.\n",
      "The time they have been reading is 240 minutes.\n",
      "The number of pages they have finished reading is $\\frac{4920}{ \n",
      "Extracted:\n",
      "Let $R$ be the number of pages Rene can finish reading in 60 minutes.\n",
      "Let $L$ be the number of pages Lulu can finish reading in 60 minutes.\n",
      "Let $C$ be the number of pages Cherry can finish reading in 60 minutes.\n",
      "We are given that Rene can finish reading 30 pages in 60 minutes, so $R = 30$.\n",
      "We are given that Lulu can read 27 pages in 60 minutes, so $L = 27$.\n",
      "We are given that Cherry can read 25 pages in 60 minutes, so $C = 25$.\n",
      "Rene finishes reading $R$ pages in 60 minutes, so he finishes reading $30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $L$ pages in 60 minutes, so she finishes reading $27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $C$ pages in 60 minutes, so she finishes reading $25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$ pages.\n",
      "They have been reading for 240 minutes.\n",
      "Let $P$ be the total number of pages they have finished reading.\n",
      "Rene finishes reading $30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$.\n",
      "They have been reading for 240 minutes.\n",
      "Let $x$ be the number of pages they have finished reading.\n",
      "Rene finishes reading $R \\times 60 = 30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $L \\times 60 = 27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $C \\times 60 = 25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$.\n",
      "The time they have been reading is 240 minutes.\n",
      "The number of pages they have finished reading is $\\frac{4920}{60} = 82$ pages.\n",
      "However, we are asked how many pages they have finished reading in total.\n",
      "Let $x$ be the number of pages they have finished reading.\n",
      "Rene finishes reading $30 \\times 60 = 1800$ pages.\n",
      "Lulu finishes reading $27 \\times 60 = 1620$ pages.\n",
      "Cherry finishes reading $25 \\times 60 = 1500$ pages.\n",
      "The total number of pages they have finished reading is $1800 + 1620 + 1500 = 4920$ pages.\n",
      "The time they have been reading is 240 minutes.\n",
      "The number of pages they have finished reading is $\\frac{4920}{\n",
      "-------------------- Question:\n",
      "Martin rings the small bell 4 times more than 1/3 as often as the big bell. If he rings both of them a combined total of 52 times, how many times does he ring the big bell? \n",
      "Answer:\n",
      "36 \n",
      "Response:\n",
      "Let $m$ be the number of times Martin rings the small bell and $b$ be the number of times he rings the big bell.\n",
      "We are given that Martin rings the small bell 4 times more than 1/3 as often as the big bell. This can be written as:\n",
      "$m = \\frac{1}{3} \\cdot b + 4$\n",
      "We are given that he rings both of them a combined total of 52 times, so $m + b = 52$.\n",
      "Now we have a system of two equations with two variables:\n",
      "1) $m = \\frac{1}{3}b + 4$\n",
      "2) $m + b = 52$\n",
      "We can substitute the first equation into the second equation to solve for $b$:\n",
      "$(\\frac{1}{3}b + 4) + b = 52$\n",
      "$\\frac{1}{3}b + b = 52 - 4$\n",
      "$\\frac{1}{3}b + b = 48$\n",
      "$\\frac{4}{3}b = 48$\n",
      "$b = 48 \\cdot \\frac{3}{4}$\n",
      "$b = 12 \\cdot 3$\n",
      "$b = 36$\n",
      "Now we can find $m$ using either equation. Let's use the first equation:\n",
      "$m = \\frac{1}{3}b + 4$\n",
      "$m = \\frac{1}{3}(36) + 4$\n",
      "$m = 12 + 4$\n",
      "$m = 16$\n",
      "Now let's check if the combined total is 52:\n",
      "$m + b = 16 + 36 = 52$\n",
      "So the number of times Martin rings the big bell is 36.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{36}$ \n",
      "Extracted:\n",
      "Let $m$ be the number of times Martin rings the small bell and $b$ be the number of times he rings the big bell.\n",
      "We are given that Martin rings the small bell 4 times more than 1/3 as often as the big bell. This can be written as:\n",
      "$m = \\frac{1}{3} \\cdot b + 4$\n",
      "We are given that he rings both of them a combined total of 52 times, so $m + b = 52$.\n",
      "Now we have a system of two equations with two variables:\n",
      "1) $m = \\frac{1}{3}b + 4$\n",
      "2) $m + b = 52$\n",
      "We can substitute the first equation into the second equation to solve for $b$:\n",
      "$(\\frac{1}{3}b + 4) + b = 52$\n",
      "$\\frac{1}{3}b + b = 52 - 4$\n",
      "$\\frac{1}{3}b + b = 48$\n",
      "$\\frac{4}{3}b = 48$\n",
      "$b = 48 \\cdot \\frac{3}{4}$\n",
      "$b = 12 \\cdot 3$\n",
      "$b = 36$\n",
      "Now we can find $m$ using either equation. Let's use the first equation:\n",
      "$m = \\frac{1}{3}b + 4$\n",
      "$m = \\frac{1}{3}(36) + 4$\n",
      "$m = 12 + 4$\n",
      "$m = 16$\n",
      "Now let's check if the combined total is 52:\n",
      "$m + b = 16 + 36 = 52$\n",
      "So the number of times Martin rings the big bell is 36.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{36}$\n",
      "-------------------- Question:\n",
      "Bert fills out the daily crossword puzzle in the newspaper every day. He uses up a pencil to fill out the puzzles every two weeks. On average, it takes him 1050 words to use up a pencil. How many words are in each crossword puzzle on average? \n",
      "Answer:\n",
      "75 \n",
      "Response:\n",
      "<reasoning>\n",
      "The problem states that Bert uses up a pencil every two weeks. This means he uses 1050 words / 2 = 525 words per two weeks. The question asks for the average number of words in each puzzle.  We need to figure out how many words he uses in total over a 1050-word period.\n",
      "\n",
      "<answer>\n",
      "1050 words / 2 weeks = 525 words/week\n",
      "525 words/week * 1050 words/puzzle = 53750 words\n",
      "</answer> \n",
      "Extracted:\n",
      "1050 words / 2 weeks = 525 words/week\n",
      "525 words/week * 1050 words/puzzle = 53750 words\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86062b-668e-4fca-97bb-144bbdf7ac96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
