{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0176fbb9-974f-4525-84ea-5a522c9d72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:46:52.167721: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-12 14:46:52.852592: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-12 14:46:52.852623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-12 14:46:52.871215: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-12 14:46:52.913412: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-12 14:46:56.524642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Mistral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.739 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f83ee27e8a4bd09a5206b156c9d832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2024  # Can increase for longer reasoning traces\n",
    "lora_rank = 32  # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"gsarti/phi3-mini-rebus-solver-fp16\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,  # False for LoRA 16bit\n",
    "    fast_inference=False,  # Enable vLLM fast inference\n",
    "    max_lora_rank=lora_rank,\n",
    "    gpu_memory_utilization=0.6,  # Reduce if out of memory\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=lora_rank,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # Remove QKVO if out of memory\n",
    "    lora_alpha=lora_rank,\n",
    "    use_gradient_checkpointing=\"unsloth\",  # Enable long context finetuning\n",
    "    random_state=3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d4f25a6-9ebf-44c5-9aba-51d4ea2cdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def estrai_soluzione(input_string):\n",
    "    # Extract only the solution\n",
    "    match = re.search(r\"Soluzione: (.+?)\\n\", input_string, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"NotFound\"\n",
    "\n",
    "def estrai_indizi(input_string):\n",
    "\n",
    "    # Extract the `[...] = relevantPart`\n",
    "    pattern = r\"\\[([^\\]]+)\\] = ([^\\n]+)\"\n",
    "    indizi = re.findall(pattern, input_string)\n",
    "    risposte = [risposta for _, risposta in indizi]\n",
    "    \n",
    "    # Extract the `... = relevantLetters`\n",
    "    pattern_sigle = r\"[-–•]?\\s*([A-Z]+(?:\\s+[A-Z]+)*)\\s*=\\s*[^\\n]+\"    \n",
    "    risposte_sigle = re.findall(pattern_sigle, input_string)\n",
    "    \n",
    "    # Combina le risposte estratte dalle parentesi e quelle singole\n",
    "    return {'letters': risposte_sigle, 'words': risposte}\n",
    "\n",
    "def estrai_primalet(input_string):\n",
    "    # Extract the first-pass (prima lettura in italian)\n",
    "    match = re.search(r\"Prima lettura: (.+?)\\n\", input_string, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"NotFound\"\n",
    "\n",
    "\n",
    "def estrai_rebus_e_chiave(testo):\n",
    "    # Extract from the problem formulation: \n",
    "    #   - the rebus problem \n",
    "    #   - the key (i.e. bounds of number of letters of the solution)\n",
    "    rebus_match = re.search(r\"Rebus:\\s*(.+?)\\s*Chiave di lettura:\", testo, re.DOTALL)\n",
    "    chiave_match = re.search(r\"Chiave di lettura:\\s*(.+)\", testo)\n",
    "\n",
    "    rebus_raw = rebus_match.group(1).strip() if rebus_match else \"\"\n",
    "    chiave = chiave_match.group(1).strip() if chiave_match else \"\"\n",
    "\n",
    "    return rebus_raw, chiave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e42bdd8-63a2-45dc-a437-f2ec68d4a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match_solution(prompts, completions, ground_truth, **kwargs) -> list[float]:\n",
    "    # Estrazione delle soluzioni\n",
    "    predicted = [estrai_soluzione(completion) for completion in completions]\n",
    "    gold = estrai_soluzione(ground_truth[0])\n",
    "    print(predicted)\n",
    "    print (gold)\n",
    "    \n",
    "    scores = []\n",
    "    for guess in predicted:\n",
    "        if guess == \"NotFound\":\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        try:\n",
    "            scores.append(1.0 if guess == gold else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores\n",
    "\n",
    "\n",
    "def perc_correct_words_solution(prompts, completions, ground_truth, **kwargs):\n",
    "    gold = estrai_soluzione(ground_truth[0]).lower().split()\n",
    "    scores = []\n",
    "    \n",
    "    for completion in completions:\n",
    "        print(completion)\n",
    "        pred = estrai_soluzione(completion)\n",
    "        print(pred)\n",
    "        if not pred:\n",
    "            continue\n",
    "\n",
    "        pred = pred.lower().split()\n",
    "        score = 0\n",
    "        for pw, gw in zip(pred, gold):\n",
    "            if pw == gw:\n",
    "                score += 1\n",
    "            elif len(pw) == len(gw):\n",
    "                score += 0.5\n",
    "        scores.append(score / len(gold))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def exact_match_primalet(prompts, completions, ground_truth, **kwargs):\n",
    "    predicted = [estrai_primalet(completion) for completion in completions]\n",
    "    golden = estrai_primalet(ground_truth[0]).lower().replace(\" \", \"\")\n",
    "    scores = []\n",
    "    for guess in predicted:\n",
    "        if guess == \"NotFound\":\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        try:\n",
    "            scores.append(1.0 if guess.lower().replace(\" \", \"\") == golden else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores\n",
    "\n",
    "\n",
    "def perc_correct_defres(prompts, completions, ground_truth, **kwargs):\n",
    "    predicted = [estrai_indizi(completion.replace(\"*\", \"\")) for completion in completions] \n",
    "    golden = estrai_indizi(ground_truth[0])\n",
    "    word_scores = []\n",
    "    letter_scores = []\n",
    "    for pred in predicted:\n",
    "        wscore = 0\n",
    "        for pw, gw in zip(pred['words'], golden['words']):\n",
    "            if pw == gw:\n",
    "                wscore += 1\n",
    "            elif len(pw) == len(gw):\n",
    "                wscore += 0.5\n",
    "        word_scores.append(wscore / len(golden['words']))\n",
    "\n",
    "        lscore = 0\n",
    "        for pw, gw in zip(pred['letters'], golden['letters']):\n",
    "            if pw.lower().replace(\" \", \"\") == gw.lower().replace(\" \", \"\"):\n",
    "                lscore += 1\n",
    "        letter_scores.append(lscore / len(golden['letters']))\n",
    "        \n",
    "    return [word_scores[i] + letter_scores[i] for i in range(len(predicted))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66c6bcd8-13bc-4c48-9d2b-e4e53154358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('gsarti/eureka-rebus', 'llm_sft', data_files=[\"train.jsonl\"], split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9013bfde-a4dc-4089-a87f-5135581c223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "492fec37-baa5-4f04-a8b1-33b4cf9b68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples, model_name):\n",
    "    \n",
    "    if model_name == \"gsarti/phi3-mini-rebus-solver-fp16\":\n",
    "        template = \"\"\"<s><|user|>\n",
    "        Risolvi gli indizi tra parentesi per ottenere una prima lettura, e usa la chiave di lettura per ottenere la soluzione del rebus.\n",
    "        \n",
    "        Rebus: {rebus}\n",
    "        Chiave risolutiva: {key}<|end|>\n",
    "        <|assistant|>\"\"\"\n",
    "        \n",
    "    elif model_name == \"gsarti/llama-3.1-8b-rebus-solver-fp16\":\n",
    "        template = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "        \n",
    "        Risolvi gli indizi tra parentesi per ottenere una prima lettura, e usa la chiave di lettura per ottenere la soluzione del rebus.\n",
    "        \n",
    "        Rebus: {rebus}\n",
    "        Chiave risolutiva: {key}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    \n",
    "    prompt_list = []\n",
    "    completion_list = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        # Estrai rebus e chiave\n",
    "        rebus_raw, chiave = estrai_rebus_e_chiave(dataset[i]['conversations'][0]['value'])\n",
    "        \n",
    "        # Crea il prompt usando il template\n",
    "        prompt = template.format(rebus=rebus_raw, key=chiave)\n",
    "        \n",
    "        # Ottieni la completion dal dataset\n",
    "        completion = dataset[i]['conversations'][1]['value']\n",
    "        \n",
    "        # Aggiungi a lista\n",
    "        prompt_list.append(prompt)\n",
    "        completion_list.append(completion)\n",
    "    \n",
    "    # Crea il DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'prompt': prompt_list,\n",
    "        'completion': completion_list\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4e0cfa0-1686-4bd3-8834-3fc45c0bfa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = formatting_prompts_func(dataset, model_name=\"gsarti/phi3-mini-rebus-solver-fp16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a433b77-1bf0-4133-b903-bfede602be11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\n        Risolvi gli indizi tra pa...</td>\n",
       "      <td>Procediamo alla risoluzione del rebus passo pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\n        Risolvi gli indizi tra pa...</td>\n",
       "      <td>Procediamo alla risoluzione del rebus passo pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\n        Risolvi gli indizi tra pa...</td>\n",
       "      <td>Procediamo alla risoluzione del rebus passo pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\n        Risolvi gli indizi tra pa...</td>\n",
       "      <td>Procediamo alla risoluzione del rebus passo pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\n        Risolvi gli indizi tra pa...</td>\n",
       "      <td>Procediamo alla risoluzione del rebus passo pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  <s><|user|>\\n        Risolvi gli indizi tra pa...   \n",
       "1  <s><|user|>\\n        Risolvi gli indizi tra pa...   \n",
       "2  <s><|user|>\\n        Risolvi gli indizi tra pa...   \n",
       "3  <s><|user|>\\n        Risolvi gli indizi tra pa...   \n",
       "4  <s><|user|>\\n        Risolvi gli indizi tra pa...   \n",
       "\n",
       "                                          completion  \n",
       "0  Procediamo alla risoluzione del rebus passo pe...  \n",
       "1  Procediamo alla risoluzione del rebus passo pe...  \n",
       "2  Procediamo alla risoluzione del rebus passo pe...  \n",
       "3  Procediamo alla risoluzione del rebus passo pe...  \n",
       "4  Procediamo alla risoluzione del rebus passo pe...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9faedc79-c0c1-4de1-afc8-81e05098fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(input['prompt'][0], return_tensors=\"pt\")[\"input_ids\"].to('cuda:0')\n",
    "outputs = model.generate(input_ids = inputs, max_new_tokens = 500, use_cache = True, do_sample=True)\n",
    "model_generations = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92dc45ba-eed6-466c-bce3-bff6c531c056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s><s><|user|> Risolvi gli indizi tra parentesi per ottenere una prima lettura, e usa la chiave di lettura per ottenere la soluzione del rebus.\\n        \\n        Rebus: A [Quello di fiori si riceve volentieri] [Vezzi visibili] RL [Dividono l\\'Argentina dal Cile] SE\\n        Chiave risolutiva: 8 9<|end|><|assistant|> Per risolvere il rebus seguendo gli indizi e la chiave di lettura, possiamo tradurre gli indizi letteralmente:\\n\\n1. [Quello di fiori si riceve volentieri] = Fiori (ma dato che il risultato deve essere un numero, non puo\\' significare letteralmente fiori)\\n2. [Vezzi visibili] = Biche (dipendente dal contesto, ma un \"biche\" o tronco arrotondato visibile potrebbe funzionare come indizio)\\n3. [Dividono l\\'Argentina dal Cile] = Meridiani (come il meridiano è uno dei divisori della Terra, ma non risolve il rebus)\\n4. SE è un codice (SE=4 nel caso del codice dei simboli di Freud e non interessa al rebus)\\n\\nPrendendo in considerazione anche la chiave risolutiva (8 9), il puzzle sembra riferirsi a numeri quindi dobbiamo cercare di tradurre gli indizi in numeri. \\n\\nInterpretando i primi indicatori:\\n\\n- \"Fiori\" potrebbe richiamare la parola in lingua latina \"Flores\", che è un numero in base axto-arabico 500. Tuttavia, questo non risolve il rebus poiché la \"F\" in latino è sostituita da un simbolo per \"Fl.\".\\n- \"Biche\" potrebbe riferirsi ad un numero, come se l\\'ispirazione fosse verso il greco antico dove \"bico\" è simile a \"βύκη\" (býkē), che è un numero in base axto-arabico 8500. Tuttavia, non ci sono parole con \"b\" in greco antico che possano rispondere anche al rebus.\\n- \"Meridiani\" potrebbe intendersi il numero 12 (il doppio meridiano corrisponde all\\'ora 12, la più comune nel mondo). Tuttavia, non risolve il rebus.\\n\\nEsegu']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c76d829-89bc-44f5-8275-3c2c0dde2a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 1,\n",
       " 'word_guesses': '',\n",
       " 'first_pass': '',\n",
       " 'solution_words': '',\n",
       " 'solution': ''}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_generation(1, model_generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec43dcb-b0ab-4caa-991e-91208165a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "regex_word_guess = '- \\[.* = (.*)'\n",
    "regex_firstpass = 'Prima lettura: (.*)'\n",
    "regex_solution_word = \"\\d+ = (.*)\"\n",
    "regex_solution = \"Soluzione: (.*)\"\n",
    "\n",
    "def parse_generation(ex_idx, ex):\n",
    "    try:\n",
    "        word_guesses = \";\".join(re.findall(regex_word_guess, ex))\n",
    "    except:\n",
    "        word_guesses = \"\"\n",
    "    try:\n",
    "        first_pass = re.findall(regex_firstpass, ex)[0]\n",
    "    except:\n",
    "        first_pass = \"\"\n",
    "    try:\n",
    "        solution_words = \";\".join(re.findall(regex_solution_word, ex))\n",
    "    except:\n",
    "        solution_words = \"\"\n",
    "    try:\n",
    "        solution = re.findall(regex_solution, ex)[0]\n",
    "    except:\n",
    "        solution = \"\"\n",
    "    return {\n",
    "        \"idx\": ex_idx,\n",
    "        \"word_guesses\": word_guesses,\n",
    "        \"first_pass\": first_pass,\n",
    "        \"solution_words\": solution_words,\n",
    "        \"solution\": solution,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7deb5182-56f8-4dfd-821f-c560c703d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = [\n",
    "    {\"conversations\": [{\"value\": \"Indovina la parola misteriosa!\"}]},\n",
    "    {\"conversations\": [{\"value\": \"Qual è la soluzione per il problema?\"}]},\n",
    "    {\"conversations\": [{\"value\": \"Risolvere il puzzle è difficile.\"}]}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78b5e61d-659c-4d6d-8c42-91dea855cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = []\n",
    "\n",
    "for i in range(4):\n",
    "    outputs = model.generate(input_ids = inputs, max_new_tokens = 500, use_cache = True, do_sample=True)\n",
    "    model_generations = tokenizer.batch_decode(outputs)\n",
    "    completions.append(model_generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "432f2037-c0b5-43fa-a2aa-b0c86245aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a5a3e94-2a5b-4159-beb6-b446c05f5a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultato per esempio 1:\n",
      "{'idx': 0, 'word_guesses': '', 'first_pass': '', 'solution_words': '', 'solution': ''}\n",
      "Risultato per esempio 2:\n",
      "{'idx': 1, 'word_guesses': '', 'first_pass': '', 'solution_words': '', 'solution': ''}\n",
      "Risultato per esempio 3:\n",
      "{'idx': 2, 'word_guesses': '', 'first_pass': '', 'solution_words': '', 'solution': ''}\n",
      "Risultato per esempio 4:\n",
      "{'idx': 3, 'word_guesses': '', 'first_pass': '', 'solution_words': '', 'solution': ''}\n"
     ]
    }
   ],
   "source": [
    "# Eseguiamo la funzione parse_generation esplicitamente per ogni esempio\n",
    "results = []\n",
    "\n",
    "for ex_idx, ex in enumerate(completions):\n",
    "    # Chiamata esplicita della funzione parse_generation\n",
    "    parsed_result = parse_generation(ex_idx, ex)\n",
    "    \n",
    "    # Stampa il risultato per ogni esempio\n",
    "    print(f\"Risultato per esempio {ex_idx + 1}:\")\n",
    "    print(parsed_result)\n",
    "    \n",
    "    # Aggiungi il risultato alla lista results\n",
    "    results.append(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c8c71-3baa-421a-b2a9-8c2eb359f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "max_prompt_length = 256\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate=5e-6,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.99,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,  # Increase to 4 for smoother training\n",
    "    num_generations=6,  # Decrease if out of memory\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_completion_length=500,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps=250,\n",
    "    save_steps=250,\n",
    "    max_grad_norm=0.1,\n",
    "    report_to=\"none\",  # Can use Weights & Biases\n",
    "    output_dir=\"outputs\",\n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[exact_match_solution, perc_correct_words_solution,\n",
    "                  exact_match_primalet, perc_correct_defres],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ada8ff-d76c-46f8-8e84-43cb2bd6b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04023f4-5a55-48a7-bdea-84a458468b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63241c1-f594-4589-9bae-594ce03aa66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
